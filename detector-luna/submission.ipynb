{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "%matplotlib inline\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/htang6/data/1x1x1/test/filenames.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-09cd51fc5d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mbboxes_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/htang6/workspace/TCAI17/DSB2017/TCAI/training/detector-seg/results/0530/res18/submit/bbox\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/htang6/data/1x1x1/test/filenames.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/htang6/data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mspacings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/htang6/data/1x1x1/test/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"spacing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/htang6/anaconda2/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/htang6/data/1x1x1/test/filenames.npy'"
     ]
    }
   ],
   "source": [
    "def getImgPath(img_dir, paths):\n",
    "    img_paths = {}\n",
    "    for path in paths:\n",
    "        files = os.listdir(os.path.join(img_dir, path))\n",
    "        files = sorted(files)\n",
    "        for f in files:\n",
    "            if f.split(\".\")[1] == \"mhd\":\n",
    "                filename = f.split(\".\")[0]\n",
    "                absolute_path = os.path.join(img_dir, os.path.join(path, f))\n",
    "                img_paths[filename] = absolute_path\n",
    "    return img_paths\n",
    "    \n",
    "bboxes_dir = \"/home/htang6/workspace/TCAI17/DSB2017/TCAI/training/detector-seg/results/0530/res18/submit/bbox\"\n",
    "filenames = np.load(\"/home/htang6/data/1x1x1/test/filenames.npy\")\n",
    "img_dir = \"/home/htang6/data\"\n",
    "spacings = np.load(os.path.join(\"/home/htang6/data/1x1x1/test/\", \"spacing\"))\n",
    "spacings = spacings.as_matrix()\n",
    "test_directory = [\"test_subset00/\", \"test_subset01/\", \"test_subset02/\",\"test_subset03/\", \"test_subset04/\"]\n",
    "save_dir = \"/home/htang6/workspace/TCAI17/DSB2017/TCAI/training/detector-seg/results/0530/res18/submit/submission\"\n",
    "\n",
    "img_paths = getImgPath(img_dir, test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission...\n"
     ]
    }
   ],
   "source": [
    "def generateSubmission(filenames, k, bboxes_dir, img_dir, spacings, save_dir):\n",
    "    \"\"\"\n",
    "    Generate the submission.csv for TCAI17\n",
    "    \n",
    "    filenames: All the patients name for testing, eg. \"LKDS-00002\"\n",
    "    k: Top k predicted bboxes per patient\n",
    "    bboxes_dir: The directory for stroing all the bounded boxes, all the bounded boxes should be named \"LKDS-00002_pbb.npy\"\n",
    "    img_dir: The directory of the original .mhd, because we need the original origin information\n",
    "    spacings: Numpy array of all the spacing information of patients\n",
    "    save_dir: Where do you want to save the submission.csv file\n",
    "    \"\"\"\n",
    "    submission = []\n",
    "\n",
    "    for patient in filenames:\n",
    "        pbb = np.load(os.path.join(bboxes_dir, \"%s_pbb.npy\" % (patient)))\n",
    "        pbb = pbb[pbb[:, 0].argsort()][::-1][:k]\n",
    "        spacing = spacings[spacings[:, 0] == patient][:, [1, 2, 3]]\n",
    "        #print spacing\n",
    "\n",
    "        _, numpyOrigin, _ = utils.load_itk_image(os.path.join(img_dir, \"%s.mhd\" % (patient)))\n",
    "\n",
    "        for p in pbb:\n",
    "            voxelCoord = p[[1, 2, 3]]\n",
    "            worldCoord = utils.voxelToWorldCoord(voxelCoord, numpyOrigin, spacing)\n",
    "            submission.append([patient, worldCoord[0][2], worldCoord[0][1], worldCoord[0][0], p[0]])\n",
    "        \n",
    "        submission = pd.DataFrame(submission, columns = [\"seriesuid\", \"coordX\", \"coordY\", \"coordZ\", \"probability\"])\n",
    "        print \"Saving submission...\"\n",
    "        submission.to_csv(save_dir, sep=',', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "k = 10\n",
    "\n",
    "submission = []\n",
    "\n",
    "for patient in filenames:\n",
    "    pbb = np.load(os.path.join(bboxes_dir, \"%s.npy_pbb.npy\" % (patient)))\n",
    "    pbb = pbb[pbb[:, 0].argsort()][::-1][:k]\n",
    "    spacing = spacings[spacings[:, 0] == patient][:, [1, 2, 3]]\n",
    "    #print spacing\n",
    "    \n",
    "    img_path = img_paths[patient]\n",
    "    _, numpyOrigin, _ = utils.load_itk_image(img_path)\n",
    "    \n",
    "    \n",
    "    #pbb = np.insert(pbb, patient, 0, axis = 0)\n",
    "    for p in pbb:\n",
    "        voxelCoord = p[[1, 2, 3]]\n",
    "#         print voxelCoord\n",
    "#         print p\n",
    "        worldCoord = utils.voxelToWorldCoord(voxelCoord, numpyOrigin, spacing)\n",
    "#         print worldCoord\n",
    "#         print utils.worldToVoxelCoord(worldCoord, numpyOrigin, spacing)\n",
    "        submission.append([patient, worldCoord[0][2], worldCoord[0][1], worldCoord[0][0], p[0]])\n",
    "\n",
    "submission = pd.DataFrame(submission, columns = [\"seriesuid\", \"coordX\", \"coordY\", \"coordZ\", \"probability\"])\n",
    "print \"Saving submission...\"\n",
    "submission.to_csv(save_dir, sep=',', index=False)\n",
    "#print submission\n",
    "#submission.to_csv(save_dir, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check coords\n",
    "double check whether the world to voxel and voxel to world is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current patient:  LKDS-00177 img_path:  /home/htang6/data/val_subset01/LKDS-00177.mhd\n",
      "[  78.99991608  205.74456787  304.71276855]\n",
      "Transformed:  [[886.0999160766602 162.2446556868409 87.21289861197027]]\n",
      "Ground truth:  [[886.0999145510001 162.244650136 87.212890625 7.30064369645]]\n",
      "\n",
      "Current patient:  LKDS-00190 img_path:  /home/htang6/data/val_subset01/LKDS-00190.mhd\n",
      "[ 219.99998474  169.07345581   68.71386719]\n",
      "Transformed:  [[597.7999847412109 104.07351220084627 -115.28610989467694]]\n",
      "Ground truth:  [[597.799987793 104.073510363 -115.28610751299999 10.2124990659]]\n",
      "\n",
      "Current patient:  LKDS-00197 img_path:  /home/htang6/data/val_subset01/LKDS-00197.mhd\n",
      "[ 173.          240.92169189   94.99662018]\n",
      "Transformed:  [[253.1 -78.73622407865099 -88.66134668958559]]\n",
      "Ground truth:  [[253.09999847400002 -78.7362232178 -88.6613503406 18.0361746161]]\n",
      "\n",
      "Current patient:  LKDS-00201 img_path:  /home/htang6/data/val_subset01/LKDS-00201.mhd\n",
      "[  62.43458939  275.2467041   247.97520447]\n",
      "Transformed:  [[-691.0999994843951 64.64865316208008 8.08739143028825]]\n",
      "Ground truth:  [[-691.09999907 64.6486662374 8.08739803485 18.2131154325]\n",
      " [-616.699997962 -16.1888788541 -8.098875522610001 27.203331613400003]]\n",
      "\n",
      "[ 136.87582397  194.38771057  231.78463745]\n",
      "Transformed:  [[-616.7000054683383 -16.18888025493868 -8.09887858252111]]\n",
      "Ground truth:  [[-691.09999907 64.6486662374 8.08739803485 18.2131154325]\n",
      " [-616.699997962 -16.1888788541 -8.098875522610001 27.203331613400003]]\n",
      "\n",
      "Current patient:  LKDS-00202 img_path:  /home/htang6/data/val_subset01/LKDS-00202.mhd\n",
      "[  52.99998856  151.12350464  233.87255859]\n",
      "Transformed:  [[686.2999885559082 -137.01749536132814 33.23155859375001]]\n",
      "Ground truth:  [[686.299987793 -137.017501877 33.231559684699995 13.5364286924]]\n",
      "\n",
      "Current patient:  LKDS-00208 img_path:  /home/htang6/data/val_subset01/LKDS-00208.mhd\n",
      "[ 113.65400696  133.41842651   62.92802429]\n",
      "Transformed:  [[123.99999851793855 -13.081490108705168 -83.07193638218739]]\n",
      "Ground truth:  [[124.0 -13.0814849094 -83.07193694729999 8.80392317898]]\n",
      "\n",
      "Current patient:  LKDS-00210 img_path:  /home/htang6/data/val_subset01/LKDS-00210.mhd\n",
      "[  65.0748291   177.13386536  197.43843079]\n",
      "Transformed:  [[395.0999730864917 198.13392713583474 16.438499647192657]]\n",
      "Ground truth:  [[395.09997558599997 198.13392103 16.4385029561 5.85979466669]]\n",
      "\n",
      "Current patient:  LKDS-00226 img_path:  /home/htang6/data/val_subset01/LKDS-00226.mhd\n",
      "[ 161.79824829  172.49334717  301.23928833]\n",
      "Transformed:  [[179.15326778179428 -10.506595301111048 118.6393888010455]]\n",
      "Ground truth:  [[179.15326618400002 -10.5065918605 118.63938548600001 35.834631860500004]]\n",
      "\n",
      "Current patient:  LKDS-00228 img_path:  /home/htang6/data/val_subset01/LKDS-00228.mhd\n",
      "[ 257.          259.11871338  148.30938721]\n",
      "Transformed:  [[419.1 -102.017159419878 -40.8265399879825]]\n",
      "Ground truth:  [[419.100006104 -102.017146744 -40.826545033 14.204155820699999]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getImgPath(img_dir, paths):\n",
    "    img_paths = {}\n",
    "    for path in paths:\n",
    "        files = os.listdir(os.path.join(img_dir, path))\n",
    "        files = sorted(files)\n",
    "        for f in files:\n",
    "            if f.split(\".\")[1] == \"mhd\":\n",
    "                filename = f.split(\".\")[0]\n",
    "                absolute_path = os.path.join(img_dir, os.path.join(path, f))\n",
    "                img_paths[filename] = absolute_path\n",
    "    return img_paths\n",
    "    \n",
    "bboxes_dir = \"/home/htang6/workspace/TCAI17/DSB2017/TCAI/training/detector/results/res18_64/bboxes/bbox\"\n",
    "filenames = np.load(\"/home/htang6/data/1x1x1/val/filenames.npy\")\n",
    "img_dir = \"/home/htang6/data\"\n",
    "spacings = np.load(os.path.join(\"/home/htang6/data/1x1x1/val/\", \"spacing\"))\n",
    "spacings = spacings.as_matrix()\n",
    "test_directory = [\"val_subset00/\", \"val_subset01/\", \"val_subset02/\",\"val_subset03/\", \"val_subset04/\"]\n",
    "\n",
    "cands_val = pd.read_csv(\"/home/htang6/data/csv/val/annotations.csv\")\n",
    "labels = cands_val.as_matrix()\n",
    "\n",
    "img_paths = getImgPath(img_dir, test_directory)\n",
    "\n",
    "# for patient in filenames:\n",
    "#     print \"Current patient: \", patient, \"img_path: \", img_paths[patient]\n",
    "#     lbb = np.load(os.path.join(bboxes_dir, \"%s.npy_lbb.npy\" % (patient)))\n",
    "#     spacing = spacings[spacings[:, 0] == patient][:, [1, 2, 3]]\n",
    "#     #print spacing\n",
    "    \n",
    "#     patient_labels = labels[labels[:, 0] == patient]\n",
    "#     patient_labels = patient_labels[:, [3, 2, 1, 4]]\n",
    "    \n",
    "#     img_path = img_paths[patient]\n",
    "#     _, numpyOrigin, _ = utils.load_itk_image(img_path)\n",
    "    \n",
    "#     for l in patient_labels:\n",
    "#         print l\n",
    "#         worldCoord_ori = l[:-1]\n",
    "#         voxelCoord_ori = utils.worldToVoxelCoord(worldCoord_ori, numpyOrigin, spacing)\n",
    "        \n",
    "#         print \"1: \", worldCoord_ori\n",
    "#         print \"2: \", voxelCoord_ori\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "for i, patient in enumerate(filenames):\n",
    "    if i <= 40:\n",
    "        continue\n",
    "    if i >= 50:\n",
    "        break\n",
    "    print \"Current patient: \", patient, \"img_path: \", img_paths[patient]\n",
    "    lbb = np.load(os.path.join(bboxes_dir, \"%s.npy_lbb.npy\" % (patient)))\n",
    "    spacing = spacings[spacings[:, 0] == patient][:, [1, 2, 3]]\n",
    "    #print spacing\n",
    "    \n",
    "    patient_labels = labels[labels[:, 0] == patient]\n",
    "    patient_labels = patient_labels[:, [3, 2, 1, 4]]\n",
    "    \n",
    "    img_path = img_paths[patient]\n",
    "    _, numpyOrigin, _ = utils.load_itk_image(img_path)\n",
    "    \n",
    "    for l in lbb:\n",
    "        voxelCoord = l[[0, 1, 2]]\n",
    "        worldCoord = utils.voxelToWorldCoord(voxelCoord, numpyOrigin, spacing)     \n",
    "        \n",
    "        print voxelCoord\n",
    "        print \"Transformed: \", worldCoord\n",
    "        print \"Ground truth: \", patient_labels\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 2-seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voxelToWorldCoord(voxelCoord, origin, spacing):\n",
    "    worldCoord = voxelCoord * spacing\n",
    "    worldCoord += origin\n",
    "    return worldCoord\n",
    "\n",
    "def worldToVoxelCoord(worldCoord, origin, spacing):\n",
    "    stretchedVoxelCoord = np.absolute(worldCoord - origin)\n",
    "    voxelCoord = stretchedVoxelCoord / spacing\n",
    "    return voxelCoord\n",
    "\n",
    "def s_to_p(s):\n",
    "    \"\"\"Convert scores array to probabilities.\"\"\"\n",
    "    from torch.autograd import Variable\n",
    "    from torch import from_numpy\n",
    "    from torch.nn import Sigmoid\n",
    "    m = Sigmoid()\n",
    "    input = Variable(from_numpy(s))\n",
    "    return  m(input).data.numpy()\n",
    "\n",
    "def generate_sub_segmentation(filenames, k, bboxes_dir, prep_dir, pred_dir=None, save_dir=None):\n",
    "    \"\"\"\n",
    "    Generate the submission.csv for TCAI17\n",
    "    \n",
    "    filenames: All the patients name for testing, eg. \"LKDS-00002\"\n",
    "    k: Top k predicted bboxes per patient\n",
    "    bboxes_dir: The directory for stroing all the bounded boxes, \n",
    "    all the bounded boxes should be named \"LKDS-00002_pbb.npy\"\n",
    "    prep_dir: The directory of the preprocessed images\n",
    "    save_dir: Where do you want to save the submission.csv file\n",
    "    \"\"\"\n",
    "    submission = []\n",
    "\n",
    "    for patient in filenames:\n",
    "        pbb = np.load(os.path.join(bboxes_dir, \"%s_pbb.npy\" % (patient)))\n",
    "        \n",
    "        if len(pbb) < 1:\n",
    "            continue\n",
    "        \n",
    "#         pred = np.load(os.path.join(pred_dir, \"%s.npy_pred.npy\" % (patient)))\n",
    "#         pbb = np.concatenate([pbb,pred], axis=1)\n",
    "        pbb[:,0] = s_to_p(pbb[:, 0])\n",
    "#         pbb[:,-1] = s_to_p(pbb[:, -1])\n",
    "        pbb = pbb[pbb[:,0] > 0.5]\n",
    "        \n",
    "#         mask = pred >= 0.5\n",
    "#         pbb = pbb[mask[:, 0], ...]\n",
    "        \n",
    "#         pbb = pbb[pbb[:, 0].argsort()][::-1][:k]\n",
    "        spacing = np.load(os.path.join(prep_dir, patient + '_spacing.npy'))\n",
    "        ebox_origin = np.load(os.path.join(prep_dir, patient + '_ebox_origin.npy'))\n",
    "        origin = np.load(os.path.join(prep_dir, patient + '_origin.npy'))\n",
    "        #print spacing\n",
    "\n",
    "        for p in pbb:\n",
    "            ebox_coord = p[[1, 2, 3]]\n",
    "            whole_img_coord = ebox_coord + ebox_origin\n",
    "            worldCoord = voxelToWorldCoord(whole_img_coord, origin, spacing)\n",
    "            submission.append([patient, worldCoord[2], worldCoord[1], worldCoord[0], p[0]])\n",
    "\n",
    "    submission = pd.DataFrame(submission, columns = [\"seriesuid\", \"coordX\", \"coordY\", \"coordZ\",\n",
    "                                                     \"probability\"])\n",
    "#     import torch\n",
    "#     m = torch.nn.Sigmoid()\n",
    "#     scores = np.array(submission['probability'])\n",
    "#     input = torch.autograd.Variable(torch.from_numpy(scores))\n",
    "#     probs = m(input).data.numpy()\n",
    "#     submission['probability'] = probs\n",
    "    \n",
    "    if save_dir != None:\n",
    "        print \"Saving submission...\"\n",
    "        submission.to_csv(save_dir, sep=',', index=False)\n",
    "    return submission\n",
    "\n",
    "def submit_wrapper(results_dir, sub, k=10):\n",
    "    \"\"\"Return dataframe of predictions and save csv file.\n",
    "    \n",
    "    sub: True if using submission (test) set; save csv as 'sub.csv'. \n",
    "         False if using val set; save csv as 'val.csv'.\n",
    "    \"\"\"\n",
    "    prep_dir = '/home/htang6/data/1x1x1_seg'\n",
    "    BASE = '/home/danielrk/tc/nod/training/detector/'\n",
    "    bboxes_dir= os.path.join(BASE, 'results', results_dir, 'bbox/')\n",
    "    if sub: \n",
    "        bboxes_dir = os.path.join(bboxes_dir, 'sub')\n",
    "        filenames = np.load(os.path.join(BASE,'filenames_test.npy'))\n",
    "        save_dir = os.path.join(BASE, 'results', results_dir, 'sub.csv')\n",
    "    else:\n",
    "        bboxes_dir = os.path.join(bboxes_dir, 'val')\n",
    "        filenames = np.load(os.path.join(BASE,'filenames_val.npy'))\n",
    "        save_dir = os.path.join(BASE, 'results', results_dir, 'val.csv')\n",
    "    return generate_sub_segmentation(filenames, k, bboxes_dir, prep_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LKDS-01004' 'LKDS-01005' 'LKDS-01009' 'LKDS-01011' 'LKDS-01013'\n",
      " 'LKDS-01014' 'LKDS-01021' 'LKDS-01023' 'LKDS-01025' 'LKDS-01026'\n",
      " 'LKDS-01029' 'LKDS-01030' 'LKDS-01032' 'LKDS-01033' 'LKDS-01034'\n",
      " 'LKDS-01037' 'LKDS-01038' 'LKDS-01039' 'LKDS-01041' 'LKDS-01042'\n",
      " 'LKDS-01043' 'LKDS-01044' 'LKDS-01047' 'LKDS-01048' 'LKDS-01049'\n",
      " 'LKDS-01050' 'LKDS-01053' 'LKDS-01054' 'LKDS-01056' 'LKDS-01058'\n",
      " 'LKDS-01061' 'LKDS-01062' 'LKDS-01063' 'LKDS-01064' 'LKDS-01065'\n",
      " 'LKDS-01066' 'LKDS-01067' 'LKDS-01068' 'LKDS-01069' 'LKDS-01071'\n",
      " 'LKDS-01073' 'LKDS-01075' 'LKDS-01077' 'LKDS-01078' 'LKDS-01081'\n",
      " 'LKDS-01083' 'LKDS-01084' 'LKDS-01085' 'LKDS-01086' 'LKDS-01087'\n",
      " 'LKDS-01088' 'LKDS-01089' 'LKDS-01091' 'LKDS-01092' 'LKDS-01093'\n",
      " 'LKDS-01094' 'LKDS-01095' 'LKDS-01098' 'LKDS-01099' 'LKDS-01100'\n",
      " 'LKDS-01102' 'LKDS-01103' 'LKDS-01104' 'LKDS-01107' 'LKDS-01108'\n",
      " 'LKDS-01109' 'LKDS-01110' 'LKDS-01112' 'LKDS-01113' 'LKDS-01114'\n",
      " 'LKDS-01115' 'LKDS-01118' 'LKDS-01120' 'LKDS-01122' 'LKDS-01123'\n",
      " 'LKDS-01125' 'LKDS-01127' 'LKDS-01128' 'LKDS-01131' 'LKDS-01132'\n",
      " 'LKDS-01134' 'LKDS-01135' 'LKDS-01136' 'LKDS-01137' 'LKDS-01138'\n",
      " 'LKDS-01142' 'LKDS-01143' 'LKDS-01144' 'LKDS-01145' 'LKDS-01148'\n",
      " 'LKDS-01149' 'LKDS-01150' 'LKDS-01152' 'LKDS-01153' 'LKDS-01154'\n",
      " 'LKDS-01155' 'LKDS-01156' 'LKDS-01157' 'LKDS-01158' 'LKDS-01159'\n",
      " 'LKDS-01163' 'LKDS-01165' 'LKDS-01166' 'LKDS-01168' 'LKDS-01169'\n",
      " 'LKDS-01170' 'LKDS-01172' 'LKDS-01176' 'LKDS-01177' 'LKDS-01178'\n",
      " 'LKDS-01181' 'LKDS-01187' 'LKDS-01188' 'LKDS-01190' 'LKDS-01191'\n",
      " 'LKDS-01194' 'LKDS-01196' 'LKDS-01203' 'LKDS-01206' 'LKDS-01210'\n",
      " 'LKDS-01211' 'LKDS-01213' 'LKDS-01214' 'LKDS-01217' 'LKDS-01218'\n",
      " 'LKDS-01221' 'LKDS-01222' 'LKDS-01223' 'LKDS-01228' 'LKDS-01230'\n",
      " 'LKDS-01231' 'LKDS-01232' 'LKDS-01234' 'LKDS-01235' 'LKDS-01236'\n",
      " 'LKDS-01238' 'LKDS-01241' 'LKDS-01242' 'LKDS-01244' 'LKDS-01245'\n",
      " 'LKDS-01246' 'LKDS-01247' 'LKDS-01249' 'LKDS-01250' 'LKDS-01254'\n",
      " 'LKDS-01255' 'LKDS-01257' 'LKDS-01263' 'LKDS-01264' 'LKDS-01266'\n",
      " 'LKDS-01267' 'LKDS-01268' 'LKDS-01269' 'LKDS-01270' 'LKDS-01271'\n",
      " 'LKDS-01272' 'LKDS-01273' 'LKDS-01277' 'LKDS-01281' 'LKDS-01282'\n",
      " 'LKDS-01283' 'LKDS-01284' 'LKDS-01289' 'LKDS-01292' 'LKDS-01295'\n",
      " 'LKDS-01297' 'LKDS-01299' 'LKDS-01300' 'LKDS-01302' 'LKDS-01304'\n",
      " 'LKDS-01307' 'LKDS-01310' 'LKDS-01312' 'LKDS-01314' 'LKDS-01316'\n",
      " 'LKDS-01317' 'LKDS-01319' 'LKDS-01321' 'LKDS-01323' 'LKDS-01324'\n",
      " 'LKDS-01325' 'LKDS-01327' 'LKDS-01328' 'LKDS-01329' 'LKDS-01331'\n",
      " 'LKDS-01332' 'LKDS-01334' 'LKDS-01335' 'LKDS-01339' 'LKDS-01340'\n",
      " 'LKDS-01343' 'LKDS-01344' 'LKDS-01345' 'LKDS-01347' 'LKDS-01348'\n",
      " 'LKDS-01349' 'LKDS-01350' 'LKDS-01351' 'LKDS-01355' 'LKDS-01360']\n",
      "Saving submission...\n",
      "       seriesuid      coordX      coordY       coordZ  probability\n",
      "0     LKDS-01004  -68.529831  -75.313234   157.200383     0.998760\n",
      "1     LKDS-01004  -91.715221  -82.576435   178.710519     0.990903\n",
      "2     LKDS-01004  -31.053646 -119.953507   141.010534     0.975262\n",
      "3     LKDS-01004  -73.156465 -154.901958    42.530063     0.966364\n",
      "4     LKDS-01004   23.876737 -227.096091   113.113311     0.897186\n",
      "5     LKDS-01004  -39.783484 -163.663809   161.219077     0.896043\n",
      "6     LKDS-01004   74.921995 -203.270694   190.327532     0.878610\n",
      "7     LKDS-01004  -95.765622 -214.499766   158.314045     0.849545\n",
      "8     LKDS-01004  112.374689 -138.590193   201.771505     0.813221\n",
      "9     LKDS-01004   84.389085 -218.882004   197.187855     0.683993\n",
      "10    LKDS-01004  -51.381564 -182.792668   144.754570     0.528473\n",
      "11    LKDS-01005  -65.213922  101.754079  -377.176797     0.998937\n",
      "12    LKDS-01005  -44.955729  218.643465  -513.247261     0.997165\n",
      "13    LKDS-01005  -71.389088  178.876682  -385.934503     0.994892\n",
      "14    LKDS-01005  136.571610  189.455871  -332.489374     0.989632\n",
      "15    LKDS-01005   90.904785  154.015215  -335.801416     0.885377\n",
      "16    LKDS-01005   94.606278  109.841068  -348.056314     0.564655\n",
      "17    LKDS-01009  -33.507922 -146.092637   -10.040669     0.999421\n",
      "18    LKDS-01009  -54.559368 -162.918809   129.506670     0.994915\n",
      "19    LKDS-01009  -94.012839 -115.196323    18.319546     0.988954\n",
      "20    LKDS-01009  -49.566324  -65.830960   113.085862     0.985037\n",
      "21    LKDS-01009 -106.209770  -81.902851   253.513155     0.975553\n",
      "22    LKDS-01009  112.996773 -241.765860   213.567045     0.958880\n",
      "23    LKDS-01009 -129.682833 -138.282545   218.192395     0.936462\n",
      "24    LKDS-01009  -54.448162 -257.604193   173.060338     0.860789\n",
      "25    LKDS-01009   80.912149 -225.735631   193.186783     0.858390\n",
      "26    LKDS-01009  -25.914848 -106.260467    17.071877     0.768455\n",
      "27    LKDS-01009  144.537680 -173.469251   181.603613     0.765335\n",
      "28    LKDS-01009  -18.424869 -253.867771   148.602305     0.646260\n",
      "29    LKDS-01009  133.839922 -214.083275   213.735637     0.611899\n",
      "...          ...         ...         ...          ...          ...\n",
      "2599  LKDS-01351  -82.375161   52.904026   207.474639     0.816084\n",
      "2600  LKDS-01351 -118.723121  112.700253   175.874725     0.761026\n",
      "2601  LKDS-01351   69.362224  216.797134   212.718383     0.738153\n",
      "2602  LKDS-01351  -31.344947  120.097418   171.566879     0.713039\n",
      "2603  LKDS-01351  -87.346719  237.335621   135.477767     0.599505\n",
      "2604  LKDS-01351   41.167929  128.939407   207.681838     0.580968\n",
      "2605  LKDS-01351  -10.754337  216.704361   180.198837     0.520023\n",
      "2606  LKDS-01355  106.127212  113.571224   171.858479     0.998515\n",
      "2607  LKDS-01355   54.169737  212.427629     8.387379     0.997595\n",
      "2608  LKDS-01355  -34.338265  193.336696   -76.090002     0.992918\n",
      "2609  LKDS-01355  -57.831970  236.279047    55.663762     0.990493\n",
      "2610  LKDS-01355 -125.717910  189.769037   108.222065     0.980897\n",
      "2611  LKDS-01355  -58.187043  230.284889    56.212391     0.918959\n",
      "2612  LKDS-01355  -46.432972  140.572023   124.415760     0.720086\n",
      "2613  LKDS-01355  -50.447218  137.828240   124.863575     0.593947\n",
      "2614  LKDS-01355   64.797304  173.292317    64.544926     0.577694\n",
      "2615  LKDS-01355  -42.206813  196.797970   -78.925424     0.501202\n",
      "2616  LKDS-01360  -86.729644  159.203282   855.813843     0.997283\n",
      "2617  LKDS-01360  -19.752860  103.872641   924.488632     0.994828\n",
      "2618  LKDS-01360   56.764302   99.276024   972.328888     0.970588\n",
      "2619  LKDS-01360  -95.185187  166.823554   856.093887     0.963402\n",
      "2620  LKDS-01360  -76.107067  211.289810   843.794807     0.928053\n",
      "2621  LKDS-01360   89.240235  199.902461   988.191711     0.908016\n",
      "2622  LKDS-01360  -84.254141  120.219725   972.190796     0.853180\n",
      "2623  LKDS-01360   68.482690   99.535767  1004.252960     0.756169\n",
      "2624  LKDS-01360   48.160799  167.221824   976.142441     0.749946\n",
      "2625  LKDS-01360  -22.995140  103.933794   971.263138     0.714687\n",
      "2626  LKDS-01360   20.319694  171.770867   976.368835     0.655413\n",
      "2627  LKDS-01360   44.431763  203.588452   787.988792     0.632299\n",
      "2628  LKDS-01360   67.557885  119.124609   927.817322     0.572206\n",
      "\n",
      "[2629 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "prep_dir = '/home/danielrk/lung/input/tianchi_prep_HU_pres'\n",
    "bboxes_dir = \"/home/htang6/workspace/detector/results/test/0/bbox/test_130\"\n",
    "pred_dir = \"/home/htang6/workspace/TCAI17/DSB2017/TCAI/training/classifier-seg/results/0622/VGG13_shortcut/results/test2\"\n",
    "save_dir = \"/home/htang6/submission.csv\"\n",
    "filenames = np.load(\"/home/htang6/workspace/detector/filenames_test2.npy\")\n",
    "blacklist = [\"LKDS-00322\", \"LKDS-00385\"]\n",
    "\n",
    "print filenames\n",
    "print generate_sub_segmentation(filenames, 30, bboxes_dir, prep_dir, save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
